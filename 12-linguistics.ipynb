{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d97819-9dbc-4334-9e69-eb4e049651fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598cb47f-d7d2-4b8a-9eca-872de1c1daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download unter https://datanizing.com/llm-tag/arxiv-2023-llm.parquet\n",
    "ai = pd.read_parquet(\"arxiv-2023-llm.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab69a8-1d07-43ec-a361-fc19a71592e7",
   "metadata": {},
   "source": [
    "# Sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9e253-63d3-40ae-a1ad-a11ad419550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab9b74-82aa-41ce-8ae7-16371153009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497b3df-51f3-417b-8559-ffe90b79efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced80f46-7a8c-44b4-87f0-270beb44e6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "ai[\"sentences\"] = None\n",
    "\n",
    "ai[\"nouns\"] = None\n",
    "ai[\"adjectives\"] = None\n",
    "ai[\"verbs\"] = None\n",
    "ai[\"lemmas\"] = None\n",
    "\n",
    "ai[\"entities\"] = None\n",
    "for i, row in tqdm(ai.iterrows(), total=len(ai)):\n",
    "\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    verbs = []\n",
    "    lemmas = []\n",
    "    nav = []\n",
    "\n",
    "    doc = nlp(row[\"title\"] + \".\\n\" + row[\"abstract\"])\n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_)\n",
    "        # noun\n",
    "        if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n",
    "            nouns.append(token.lemma_)\n",
    "            nav.append(token.lemma_)\n",
    "        # adjective\n",
    "        if token.pos_ == \"ADJ\" or token.pos_ == \"ADV\":\n",
    "            adjectives.append(token.lemma_)\n",
    "            nav.append(token.lemma_)\n",
    "        # verb\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verbs.append(token.lemma_)\n",
    "            nav.append(token.lemma_)\n",
    "\n",
    "    sentences = []\n",
    "    for sentence in doc.sents:\n",
    "        sentences.append(str(sentence).strip())\n",
    "        \n",
    "    ai.at[i, \"sentences\"] = sentences\n",
    "\n",
    "    ai.at[i, \"nouns\"] = nouns\n",
    "    ai.at[i, \"adjectives\"] = adjectives\n",
    "    ai.at[i, \"verbs\"] = verbs\n",
    "    ai.at[i, \"lemmas\"] = lemmas\n",
    "\n",
    "    ai.at[i, \"entities\"] = list([str(e) for e in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add606a8-f4a7-45cc-a95d-44d5ad6fb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.to_parquet(\"arxiv-2023-llm-linguistic.parquet\", compression=\"zstd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
